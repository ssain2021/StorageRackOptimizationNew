{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################  Storage_Optimization.ipynb  ####################################\n",
    "# Author: Sukhendu Sain\n",
    "# Description: Main file of codebase. Houses main code\n",
    "# Data: 23-Nov-2024\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries, Utils, and Config Files\n",
    "import utils\n",
    "from config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "import matplotlib.pyplot as plt\n",
    "# import importlib\n",
    "# importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (AKINS FoMoCo_Piece_Sales_112222_YTD.xlsx) into Dataframe\n",
    "# df_Akins = utils.read_excel(AKINS_FOMO_FILE_PATH)\n",
    "# df_Akins['Part#'] = df_Akins['Part#'].apply(lambda a: \"\".join(str(a).split('-')))\n",
    "# if print_df_after_import: utils.print_df(df_Akins, 200) # Print the Dataframe\n",
    "# ~1-2secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (GPARTS Part Measures.xlsx) into Dataframe\n",
    "df_Gparts = utils.read_excel(GPARTS_FILE_PATH)\n",
    "if print_df_after_import: utils.print_df(df_Gparts) # Print the Dataframe\n",
    "# ~50-60secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Wholesale JAN_Oct_Parts_Ranking_Counter_Invoices_All_Brands.xlsx) into Dataframe\n",
    "df_Wholesale = utils.read_excel(WHOLESALE_FILE_PATH)\n",
    "\n",
    "# Clean the Wholesale Dataframe\n",
    "df_Wholesale['Description'] = df_Wholesale['Description'].astype(str)\n",
    "df_Wholesale = df_Wholesale.drop(columns=[col for col in df_Wholesale.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Wholesale = df_Wholesale[(df_Wholesale['Vendor'] == 'FOR')].reset_index()\n",
    "df_Wholesale.loc[df_Wholesale['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Avg. Cost'] = df_Wholesale['Description'].apply(lambda x: [i for i in x.strip().split(\"      \")][-1])\n",
    "df_Wholesale.loc[df_Wholesale['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Description'] = df_Wholesale['Description'].apply(lambda x: \"     \".join([i for i in x.strip().split(\"      \")][:-1]))\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Wholesale) # Print the Dataframe\n",
    "# ~12-15secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Service JAN_Oct_Parts_Ranking_ROs_All_Brands.xlsx) into Dataframe\n",
    "df_Service = utils.read_excel(SERVICE_FILE_PATH)\n",
    "\n",
    "# Clean the Service Dataframe\n",
    "df_Service['Description'] = df_Service['Description'].astype(str)\n",
    "df_Service = df_Service.drop(columns=[col for col in df_Service.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Service = df_Service[(df_Service['Vendor'] == 'FOR')].reset_index()\n",
    "df_Service.loc[df_Service['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Avg. Cost'] = df_Service['Description'].apply(lambda x: [i for i in x.strip().split(\"      \")][-1])\n",
    "df_Service.loc[df_Service['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Description'] = df_Service['Description'].apply(lambda x: \"     \".join([i for i in x.strip().split(\"      \")][:-1]))\n",
    "df_Service.loc[df_Service['Qty Sold'].apply(lambda x: len(str(x).split(\"      \")) > 1), 'Dollars Sold'] = df_Service['Qty Sold'].apply(lambda x: [i for i in str(x).strip().split(\"      \")][-1])\n",
    "df_Service.loc[df_Service['Qty Sold'].apply(lambda x: len(str(x).split(\"      \")) > 1), 'Qty Sold'] = df_Service['Qty Sold'].apply(lambda x: \"     \".join([i for i in str(x).strip().split(\"      \")][:-1]))\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Service, 100) # Print the Dataframe\n",
    "# ~5-6secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Counter Pad) into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing & Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Big Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will have the Columns - 'Part Number', 'Part Desc.', 'Active', 'Sold (Pcs.)', '0Dimensions', 'Length/Depth', 'Width', 'Height', 'Zone', 'Storage Type', 'Sub Storage', 'Number of Storage needed'\n",
    "# It will have all the rows with common part nos. from 3 Files, having Appropriate Sold Pcs. Values, and Dimensions\n",
    "\n",
    "main_list = [] # Initialize the New List, which will hole all rows before turning into DF\n",
    "gParts_PartNos = set(df_Gparts['Svc Part Number']) # Get a Set of all Part Nos. of GParts\n",
    "\n",
    "\n",
    "# Wholesale\n",
    "common_part_numbers = gParts_PartNos & set(df_Wholesale['Part Number'])\n",
    "df_PreMerge = df_Gparts.loc[df_Gparts['Svc Part Number'].isin(common_part_numbers), ['Svc Part Number', 'Svc Part Number Description', 'Is Active?', 'Prod Att - Length', 'Prod Att- Width', 'Prod Att - Height']]\n",
    "for pn, pddesc, ac, dp, wd, ht in zip(df_PreMerge['Svc Part Number'], df_PreMerge['Svc Part Number Description'], df_PreMerge['Is Active?'], df_PreMerge['Prod Att - Length'], df_PreMerge['Prod Att- Width'], df_PreMerge['Prod Att - Height']):\n",
    "    main_list.append([pn, pddesc, \"\", \"Wholesale\", ac, df_Wholesale[df_Wholesale['Part Number'] == pn]['Sold'].values[0], 0, 0, False, dp, wd, ht, \"\", \"\", \"\", \"\", \"\"])\n",
    "\n",
    "\n",
    "# Service\n",
    "common_part_numbers = gParts_PartNos & set(df_Service['* indicates a superseded part\\nPart Number'])\n",
    "df_PreMerge = df_Gparts.loc[df_Gparts['Svc Part Number'].isin(common_part_numbers), ['Svc Part Number', 'Svc Part Number Description', 'Is Active?', 'Prod Att - Length', 'Prod Att- Width', 'Prod Att - Height']]\n",
    "for pn, pddesc, ac, dp, wd, ht in zip(df_PreMerge['Svc Part Number'], df_PreMerge['Svc Part Number Description'], df_PreMerge['Is Active?'], df_PreMerge['Prod Att - Length'], df_PreMerge['Prod Att- Width'], df_PreMerge['Prod Att - Height']):\n",
    "    main_list.append([pn, pddesc, \"\", \"Service\", ac, 0, df_Service[df_Service['* indicates a superseded part\\nPart Number'] == pn]['Qty Sold'].values[0], 0, False, dp, wd, ht, \"\", \"\", \"\", \"\", \"\"])\n",
    "\n",
    "\n",
    "# Create the Main Dataframe\n",
    "df_Main = pd.DataFrame(main_list)\n",
    "df_Main.columns = ['Part#', 'Part Desc.', 'Part Category', 'DataSource', 'Active', 'Wholesale Sold', 'Service Sold', \"Total Sold\", '0Dimensions', 'Depth', 'Width', 'Height', 'Zone', 'StorageType', 'SubStorage', 'Num. Storage Required', \"Bin Location\"]\n",
    "\n",
    "# Merge the Parts present in both Service and Wholesale (Duplicates)\n",
    "gbParts = df_Main.groupby('Part#').count()[df_Main.groupby('Part#').count()['Part Desc.'] == 2].index.to_list()\n",
    "for pn in gbParts:\n",
    "    df_Main.loc[(df_Main['Part#'] == pn) & (df_Main['DataSource'] == \"Wholesale\"), \"Service Sold\"] = df_Main.loc[(df_Main['Part#'] == pn) & (df_Main['DataSource'] == \"Service\"), \"Service Sold\"].values[0]\n",
    "    df_Main = df_Main[(df_Main['Part#'] != pn) | (df_Main['DataSource'] == \"Wholesale\")]\n",
    "# Set 0Dimensions\n",
    "df_Main.loc[(df_Main[\"Depth\"] == 0) | (df_Main[\"Height\"] == 0) | (df_Main[\"Width\"] == 0), \"0Dimensions\"] = True\n",
    "# Drop 0Dimensions Rows if drop0Dims\n",
    "if drop0Dims: df_Main = df_Main[df_Main[\"0Dimensions\"] == False]\n",
    "# Set Total_Sold\n",
    "df_Main[\"Total Sold\"] = df_Main[\"Wholesale Sold\"].astype(int) + df_Main[\"Service Sold\"].astype(int)\n",
    "# Sort by 'Total Sold'\n",
    "df_Main = df_Main.sort_values('Total Sold', ascending=False)\n",
    "# Reset Index\n",
    "df_Main = df_Main.reset_index(drop=True)\n",
    "\n",
    "utils.print_df(df_Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_categorization(df_toBeCategorized):\n",
    "    # TODO: Add more categories\n",
    "    for i in range(df_toBeCategorized.shape[0]):\n",
    "        desc = \"-\".join(df_toBeCategorized.loc[i, \"Part Desc.\"].split(\"-\")[1:])\n",
    "        category = \"\"\n",
    "        if \"rivet\" in desc.lower():\n",
    "            category = \"Rivet\"\n",
    "        elif (\"blade\" in desc.lower()) & (\"wiper\" in desc.lower()):\n",
    "            category = \"Wiper Blade\"        \n",
    "        elif (\"arm\" in desc.lower()) & (\"wiper\" in desc.lower()):\n",
    "            category = \"Wiper Arm\"\n",
    "        elif (\"v-belt\" in desc.lower()):\n",
    "            category = \"V-Belt\"\n",
    "        elif (\"belt\" in desc.lower()) & (\"retractor\" not in desc.lower()) & (\"hole\" not in desc.lower()) & (\"cover\" not in desc.lower()):\n",
    "            category = \"Belt\"\n",
    "        # elif (\"hose\" in desc.lower()) & (\"vent\" not in desc.lower()) & (\"connect\" not in desc.lower() & (\"radiator\" not in desc.lower()& (\"heater\" not in desc.lower()):\n",
    "        #     category = \"Hose\"\n",
    "\n",
    "        df_toBeCategorized.loc[i, 'Part Category'] = category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Zoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clarify for other Zones and merge the 2 below functions\n",
    "\n",
    "## Main Function for Apply Zoning\n",
    "def Apply_Zoning2(df_toBeZoned, zones, soldColName='Total Sold', zoneColName='Zone'): \n",
    "    df_toBeZoned.loc[:, zoneColName] = df_toBeZoned[soldColName].apply(lambda x: next((zone for zone, ratio in zones.items() if x >= ratio), list(zones.keys())[0]))\n",
    "    df_toBeZoned.loc[df_toBeZoned[soldColName] < 1, zoneColName] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the Apply_Zoning on df_Main\n",
    "Apply_Zoning2(df_Main, zones, 'Total Sold', 'Zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check each Zone's number of Part Numbers\n",
    "df_Main['Zone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specialty Storage Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpecialityStorage(pdesc, depth, width, height):\n",
    "    # Initialize the empty Variables\n",
    "    storageType = \"\"\n",
    "    subStorage = \"\"\n",
    "\n",
    "    # Parsing for Battery\n",
    "    if pdesc.split(\"-\")[-1].trim() == \"Battery\":\n",
    "        storageType = \"Battery Specialty Storage\"\n",
    "        subStorage = \"48-inch Deep- 48-inch Wide- 3-Level Sloped Shelving\"\n",
    "    # Parsing for Tire\n",
    "    elif pdesc.split(\"-\")[-1].trim() == \"Tire\":\n",
    "        storageType = \"Tire Specialty Storage\"\n",
    "        subStorage = \"\"           \n",
    "    # Parsing for Bumper Cover\n",
    "    elif (\"Bumper\" in pdesc) & (\"Cover\" in pdesc):\n",
    "        storageType = \"Bumper Cover Specialty Storage\"\n",
    "        subStorage = \"\"\n",
    "    # For Hanging Storage\n",
    "    elif ((depth > 24) | (width > 24) | (height > 24)) & ((depth < 4) | (width < 4) | (height < 24)):\n",
    "        storageType = \"Hanging Speciality Storage\"\n",
    "        # TODO: Clarify to get the SKU Count and Fix this\n",
    "        skuCount = 10\n",
    "        if skuCount <= 10: \n",
    "            subStorage = \"6-inch Hooks\"\n",
    "        elif 10 < skuCount <= 20:\n",
    "            subStorage = \"12-inch Hooks\"\n",
    "\n",
    "    return storageType, subStorage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function for Storage Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStorage(zone, pdesc, depth, width, height):\n",
    "    # Initialize the empty Variables\n",
    "    storageType = \"\"\n",
    "    subStorage = \"\"\n",
    "\n",
    "    if (zone == \"Red Hot\") | (zone == \"Red\"):\n",
    "        storageType, subStorage = utils.getRedHotStorage(depth, width, height)\n",
    "    elif zone == \"Orange\":\n",
    "        storageType, subStorage = utils.getOrangeStorage(depth, width, height)\n",
    "    elif zone == \"Yellow\":\n",
    "        storageType, subStorage = utils.getYellowStorage(depth, width, height)\n",
    "    elif zone == \"Green\":   \n",
    "        storageType, subStorage = utils.getGreenStorage(depth, width, height)\n",
    "    elif zone == \"Blue\":\n",
    "        storageType, subStorage = utils.getBlueStorage(depth, width, height)\n",
    "\n",
    "    return storageType, subStorage # Return the Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the Storage Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_Main.shape[0]):\n",
    "    # Set the Dimensions of the Data into Variables\n",
    "    depth = df_Main.loc[i, \"Depth\"]\n",
    "    height = df_Main.loc[i, \"Height\"]\n",
    "    width = df_Main.loc[i, \"Width\"]\n",
    "\n",
    "    zone = df_Main.loc[i, \"Zone\"]\n",
    "    pdesc = df_Main.loc[i, \"Part Desc.\"]\n",
    "\n",
    "    # If any dimension is zero, set empty Storage\n",
    "    if df_Main.loc[i, \"0Dimensions\"] == True:\n",
    "        df_Main.loc[i, \"StorageType\"] = \"\"\n",
    "        df_Main.loc[i, \"SubStorage\"] = \"\"\n",
    "        continue\n",
    "\n",
    "    # Set Storage of the Parts\n",
    "    df_Main.loc[i, \"StorageType\"], df_Main.loc[i, \"SubStorage\"] = getStorage(zone, pdesc, depth, width, height)\n",
    "\n",
    "# TODO & CLARIFICATIŌN --  Calculate Tire Carousel Model Selection:\n",
    "#df_Main[df_Main['StorageType'] == 'Tire Specialty Storage']['SubStorage'] = 'Standard Carousel Model' if df_Main[df_Main['StorageType'] == 'Tire Specialty Storage'][df_Main['SubStorage'] == '<=28-inches'].shape[0] / df_Main[df_Main['StorageType'] == 'Tire Specialty Storage'].shape[0] >= TIRE_PERCENT2 else 'Large Carousel Model'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_df(df_Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Main.to_excel('FinalDataset.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Main[\"StorageType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Main[(df_Main[\"0Dimensions\"] == True) & (df_Main[\"StorageType\"] == \"\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
