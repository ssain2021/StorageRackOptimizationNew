{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Comment\n",
    "# ! Very Important Errors or things which must be fixed or be in attention immediately\n",
    "# TODO: Things remaining to do\n",
    "# ? Questions\n",
    "# * Some Messages or Notes\n",
    "# ^ Important Notes, Messages or things which may need attention in future\n",
    "# & Important Commented out Code\n",
    "# ~ Purple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#^###############################  Storage_Optimization.ipynb  ####################################\n",
    "# ^ Author: Sukhendu Sain\n",
    "# ^ Description: Main file of codebase. Houses main code\n",
    "# ^ Data: 23-Nov-2024\n",
    "#^################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries, Utils, and Config Files\n",
    "import utils\n",
    "from config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# import importlib\n",
    "# importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (AKINS FoMoCo_Piece_Sales_112222_YTD.xlsx) into Dataframe\n",
    "# df_Akins = utils.read_excel(AKINS_FOMO_FILE_PATH)\n",
    "# df_Akins['Part#'] = df_Akins['Part#'].apply(lambda a: \"\".join(str(a).split('-')))\n",
    "# if print_df_after_import: utils.print_df(df_Akins, 200) # Print the Dataframe\n",
    "# ~1-2secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (GPARTS Part Measures.xlsx) into Dataframe\n",
    "df_Gparts = utils.read_excel(GPARTS_FILE_PATH)\n",
    "if print_df_after_import: utils.print_df(df_Gparts) # Print the Dataframe\n",
    "# ~50-60secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Wholesale JAN_Oct_Parts_Ranking_Counter_Invoices_All_Brands.xlsx) into Dataframe\n",
    "df_Wholesale = utils.read_excel(WHOLESALE_FILE_PATH)\n",
    "\n",
    "# Clean the Wholesale Dataframe\n",
    "df_Wholesale['Description'] = df_Wholesale['Description'].astype(str)\n",
    "df_Wholesale = df_Wholesale.drop(columns=[col for col in df_Wholesale.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Wholesale = df_Wholesale[(df_Wholesale['Vendor'] == 'FOR')].reset_index()\n",
    "df_Wholesale.loc[df_Wholesale['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Avg. Cost'] = df_Wholesale['Description'].apply(lambda x: [i for i in x.strip().split(\"      \")][-1])\n",
    "df_Wholesale.loc[df_Wholesale['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Description'] = df_Wholesale['Description'].apply(lambda x: \"     \".join([i for i in x.strip().split(\"      \")][:-1]))\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Wholesale) # Print the Dataframe\n",
    "# ~12-15secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Service JAN_Oct_Parts_Ranking_ROs_All_Brands.xlsx) into Dataframe\n",
    "df_Service = utils.read_excel(SERVICE_FILE_PATH)\n",
    "\n",
    "# Clean the Service Dataframe\n",
    "df_Service['Description'] = df_Service['Description'].astype(str)\n",
    "df_Service = df_Service.drop(columns=[col for col in df_Service.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Service = df_Service[(df_Service['Vendor'] == 'FOR')].reset_index()\n",
    "df_Service.loc[df_Service['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Avg. Cost'] = df_Service['Description'].apply(lambda x: [i for i in x.strip().split(\"      \")][-1])\n",
    "df_Service.loc[df_Service['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Description'] = df_Service['Description'].apply(lambda x: \"     \".join([i for i in x.strip().split(\"      \")][:-1]))\n",
    "df_Service.loc[df_Service['Qty Sold'].apply(lambda x: len(str(x).split(\"      \")) > 1), 'Dollars Sold'] = df_Service['Qty Sold'].apply(lambda x: [i for i in str(x).strip().split(\"      \")][-1])\n",
    "df_Service.loc[df_Service['Qty Sold'].apply(lambda x: len(str(x).split(\"      \")) > 1), 'Qty Sold'] = df_Service['Qty Sold'].apply(lambda x: \"     \".join([i for i in str(x).strip().split(\"      \")][:-1]))\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Service, 100) # Print the Dataframe\n",
    "# ~5-6secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Counter Pad) into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing & Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Big Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m gbParts \u001b[38;5;241m=\u001b[39m df_Main\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPart#\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcount()[df_Main\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPart#\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcount()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPart Desc.\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pn \u001b[38;5;129;01min\u001b[39;00m gbParts:\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mdf_Main\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_Main\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPart#\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_Main\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDataSource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWholesale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mService Sold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m df_Main\u001b[38;5;241m.\u001b[39mloc[(df_Main[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPart#\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m pn) \u001b[38;5;241m&\u001b[39m (df_Main[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataSource\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mService\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mService Sold\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     30\u001b[0m     df_Main \u001b[38;5;241m=\u001b[39m df_Main[(df_Main[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPart#\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m pn) \u001b[38;5;241m|\u001b[39m (df_Main[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataSource\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWholesale\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Set 0Dimensions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\s_sai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\s_sai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:1942\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1941\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1942\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\s_sai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:2035\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   2032\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2033\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m   2034\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loc \u001b[38;5;129;01min\u001b[39;00m ilocs:\n\u001b[1;32m-> 2035\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\s_sai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexing.py:2175\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[1;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mvoid:\n\u001b[0;32m   2166\u001b[0m         \u001b[38;5;66;03m# This means we're expanding, with multiple columns, e.g.\u001b[39;00m\n\u001b[0;32m   2167\u001b[0m         \u001b[38;5;66;03m#     df = pd.DataFrame({'A': [1,2,3], 'B': [4,5,6]})\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[38;5;66;03m# Here, we replace those temporary `np.void` columns with\u001b[39;00m\n\u001b[0;32m   2171\u001b[0m         \u001b[38;5;66;03m# columns of the appropriate dtype, based on `value`.\u001b[39;00m\n\u001b[0;32m   2172\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[:, loc] \u001b[38;5;241m=\u001b[39m construct_1d_array_from_inferred_fill_value(\n\u001b[0;32m   2173\u001b[0m             value, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   2174\u001b[0m         )\n\u001b[1;32m-> 2175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplane_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\s_sai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1338\u001b[0m, in \u001b[0;36mBlockManager.column_setitem\u001b[1;34m(self, loc, idx, value, inplace_only)\u001b[0m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1337\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m col_mgr\u001b[38;5;241m.\u001b[39msetitem((idx,), value)\n\u001b[1;32m-> 1338\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_to_warn:\n\u001b[0;32m   1341\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1342\u001b[0m         COW_WARNING_GENERAL_MSG,\n\u001b[0;32m   1343\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1344\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1345\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\s_sai\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1149\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace, refs)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1148\u001b[0m         blk\u001b[38;5;241m.\u001b[39mset_inplace(blk_locs, value_getitem(val_locs))\n\u001b[1;32m-> 1149\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     unfit_mgr_locs\u001b[38;5;241m.\u001b[39mappend(blk\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mas_array[blk_locs])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# * It will have the Columns - 'Part Number', 'Part Desc.', 'Active', 'Sold (Pcs.)', '0Dimensions', 'Length/Depth', 'Width', 'Height', 'Zone', 'Storage Type', 'Sub Storage', 'Number of Storage needed'\n",
    "# It will have all the rows with common part nos. from 3 Files, having Appropriate Sold Pcs. Values, and Dimensions\n",
    "\n",
    "main_list = [] # Initialize the New List, which will hold all rows before turning into DF\n",
    "gParts_PartNos = set(df_Gparts['Svc Part Number']) # Get a Set of all Part Nos. of GParts\n",
    "\n",
    "\n",
    "# Wholesale\n",
    "common_part_numbers = gParts_PartNos & set(df_Wholesale['Part Number'])\n",
    "df_PreMerge = df_Gparts.loc[df_Gparts['Svc Part Number'].isin(common_part_numbers), ['Svc Part Number', 'Svc Part Number Description', 'Is Active?', 'Prod Att - Length', 'Prod Att- Width', 'Prod Att - Height']]\n",
    "for pn, pddesc, ac, dp, wd, ht in zip(df_PreMerge['Svc Part Number'], df_PreMerge['Svc Part Number Description'], df_PreMerge['Is Active?'], df_PreMerge['Prod Att - Length'], df_PreMerge['Prod Att- Width'], df_PreMerge['Prod Att - Height']):\n",
    "    main_list.append([pn, pddesc, \"\", \"Wholesale\", ac, df_Wholesale[df_Wholesale['Part Number'] == pn]['Sold'].values[0], 0, 0, False, dp, wd, ht, \"\", \"\", \"\", \"\", 0, \"\", \"\"])\n",
    "\n",
    "\n",
    "# Service\n",
    "common_part_numbers = gParts_PartNos & set(df_Service['* indicates a superseded part\\nPart Number'])\n",
    "df_PreMerge = df_Gparts.loc[df_Gparts['Svc Part Number'].isin(common_part_numbers), ['Svc Part Number', 'Svc Part Number Description', 'Is Active?', 'Prod Att - Length', 'Prod Att- Width', 'Prod Att - Height']]\n",
    "for pn, pddesc, ac, dp, wd, ht in zip(df_PreMerge['Svc Part Number'], df_PreMerge['Svc Part Number Description'], df_PreMerge['Is Active?'], df_PreMerge['Prod Att - Length'], df_PreMerge['Prod Att- Width'], df_PreMerge['Prod Att - Height']):\n",
    "    main_list.append([pn, pddesc, \"\", \"Service\", ac, 0, df_Service[df_Service['* indicates a superseded part\\nPart Number'] == pn]['Qty Sold'].values[0], 0, False, dp, wd, ht, \"\", \"\", \"\", \"\", 0, \"\", \"\"])\n",
    "\n",
    "\n",
    "# Create the Main Dataframe\n",
    "df_Main = pd.DataFrame(main_list)\n",
    "df_Main.columns = ['Part#', 'Part Desc.', 'Part Category', 'DataSource', 'Active', 'Wholesale Sold', 'Service Sold', \"Total Sold\", '0Dimensions', 'Depth', 'Width', 'Height', 'Zone', 'StorageType', 'SubStorage', 'Bin Type', 'OH Inventory', 'Num. Storage Required', \"Bin Location\"]\n",
    "\n",
    "# Merge the Parts present in both Service and Wholesale (Duplicates)\n",
    "gbParts = df_Main.groupby('Part#').count()[df_Main.groupby('Part#').count()['Part Desc.'] == 2].index.to_list()\n",
    "for pn in gbParts:\n",
    "    df_Main.loc[(df_Main['Part#'] == pn) & (df_Main['DataSource'] == \"Wholesale\"), \"Service Sold\"] = df_Main.loc[(df_Main['Part#'] == pn) & (df_Main['DataSource'] == \"Service\"), \"Service Sold\"].values[0]\n",
    "    df_Main = df_Main[(df_Main['Part#'] != pn) | (df_Main['DataSource'] == \"Wholesale\")]\n",
    "# Set 0Dimensions\n",
    "df_Main.loc[(df_Main[\"Depth\"] == 0) | (df_Main[\"Height\"] == 0) | (df_Main[\"Width\"] == 0), \"0Dimensions\"] = True\n",
    "# Drop 0Dimensions Rows if drop0Dims\n",
    "if drop0Dims: df_Main = df_Main[df_Main[\"0Dimensions\"] == False]\n",
    "# Set Total_Sold\n",
    "df_Main[\"Total Sold\"] = df_Main[\"Wholesale Sold\"].astype(int) + df_Main[\"Service Sold\"].astype(int)\n",
    "# Sort by 'Total Sold'\n",
    "df_Main = df_Main.sort_values('Total Sold', ascending=False)\n",
    "# ^ Add Random Values for OH Inventory temporarily\n",
    "df_Main[\"OH Inventory\"] = np.random.choice(np.arange(20), size=len(df_Main), replace=True)\n",
    "# Reset Index\n",
    "df_Main = df_Main.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * TESTING SECTION ---- Change some data Manually\n",
    "df_Main.loc[df_Main[\"Part#\"] == '6F2Z1A189A', [\"Part Desc.\",\"0Dimensions\", \"Depth\", \"Height\", \"Width\", \"OH Inventory\"]] = [\"6F2Z1A189A-TIRE\",False, 28,28,3,100]\n",
    "df_Main.loc[df_Main[\"Part#\"] == '7L1Z1A189A', [\"Part Desc.\",\"0Dimensions\", \"Depth\", \"Height\", \"Width\", \"OH Inventory\"]] = [\"7L1Z1A189A-TIRE\",False, 34,34,3.5,50]\n",
    "df_Main.loc[df_Main[\"Part#\"] == '9OO1183106436', [\"0Dimensions\", \"Depth\", \"Height\", \"Width\", \"OH Inventory\"]] = [False, 30,30,3,1000]\n",
    "df_Main.loc[df_Main[\"Part#\"] == '9OO439510', [\"0Dimensions\", \"Depth\", \"Height\", \"Width\", \"OH Inventory\"]] = [False, 45,45,4.5,500]\n",
    "df_Main.loc[df_Main[\"Part#\"] == '9OO1732002500', [\"0Dimensions\", \"Depth\", \"Height\", \"Width\", \"OH Inventory\"]] = [False, 50,50,5,250]\n",
    "df_Main.loc[df_Main[\"Part#\"] == '9OO3004901', [\"0Dimensions\", \"Depth\", \"Height\", \"Width\", \"OH Inventory\"]] = [False, 40,40,4,25]\n",
    "df_Main[['TIRE' in s for s in df_Main[\"Part Desc.\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_df(df_Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###  ^ PART CATEGORIZATION. TO DO.  BUT Client Will Share Actual Part Category\n",
    "def part_categorization(df_toBeCategorized):\n",
    "    # TODO: Add more categories\n",
    "    for i in range(df_toBeCategorized.shape[0]):\n",
    "        desc = \"-\".join(df_toBeCategorized.loc[i, \"Part Desc.\"].split(\"-\")[1:])\n",
    "        category = \"\"\n",
    "        if \"rivet\" in desc.lower():\n",
    "            category = \"Rivet\"\n",
    "        elif (\"blade\" in desc.lower()) & (\"wiper\" in desc.lower()):\n",
    "            category = \"Wiper Blade\"        \n",
    "        elif (\"arm\" in desc.lower()) & (\"wiper\" in desc.lower()):\n",
    "            category = \"Wiper Arm\"\n",
    "        elif (\"v-belt\" in desc.lower()):\n",
    "            category = \"V-Belt\"\n",
    "        elif (\"belt\" in desc.lower()) & (\"retractor\" not in desc.lower()) & (\"hole\" not in desc.lower()) & (\"cover\" not in desc.lower()):\n",
    "            category = \"Belt\"\n",
    "        # elif (\"hose\" in desc.lower()) & (\"vent\" not in desc.lower()) & (\"connect\" not in desc.lower() & (\"radiator\" not in desc.lower()& (\"heater\" not in desc.lower()):\n",
    "        #     category = \"Hose\"\n",
    "\n",
    "        df_toBeCategorized.loc[i, 'Part Category'] = category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Zoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## * Main Function for Apply Zoning\n",
    "def Apply_Zoning(df_toBeZoned, zones, soldColName='Total Sold', zoneColName='Zone'): \n",
    "    df_toBeZoned.loc[:, zoneColName] = df_toBeZoned[soldColName].apply(lambda x: next((zone for zone, ratio in zones.items() if x >= ratio), list(zones.keys())[0]))\n",
    "    df_toBeZoned.loc[df_toBeZoned[soldColName] < 0, zoneColName] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the Apply_Zoning on df_Main\n",
    "Apply_Zoning(df_Main, zones, 'Total Sold', 'Zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check each Zone's number of Part Numbers\n",
    "df_Main['Zone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specialty Storage Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Bin Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumOfBin(depth, width, height, raw_bin_dim, ohInven):\n",
    "    # ^ Raw Bin Dimensions has this format :-  Height_Depth_Width\n",
    "    FILL_FACTOR = 0.7       #  70% Filling, 30% Open Space for DRAWER / RACK / SHELVE\n",
    "\n",
    "    if (raw_bin_dim != \"\") and (ohInven > 0):\n",
    "        bin_height = float(raw_bin_dim.split(\"_\")[1])\n",
    "        bin_depth = float(raw_bin_dim.split(\"_\")[2])\n",
    "        bin_width = float(raw_bin_dim.split(\"_\")[3])\n",
    "\n",
    "        if raw_bin_dim.split(\"_\")[0] == \"BR\":        ###  HANDLE BATTERY\n",
    "            return round((bin_depth / width), 2)\n",
    "\n",
    "        if raw_bin_dim.split(\"_\")[0] == \"TR\":        ###  HANDLE TIRES \n",
    "            return 0\n",
    "        \n",
    "        if raw_bin_dim.split(\"_\")[0] == \"BC\":        ###  HANDLE BUMPER COVERS  \n",
    "            return 0\n",
    "        if raw_bin_dim.split(\"_\")[0] == \"HS\":        ###  HANDLE HANGING ITEMS \n",
    "            return 0\n",
    "            \n",
    "\n",
    "\n",
    "        # numOfBins = math.ceil(ohInven / (math.floor(bin_depth / depth) * math.floor(bin_width / width) * math.floor(bin_height / height)))\n",
    "        volBin = FILL_FACTOR * bin_height * bin_depth * bin_width       ###  Available Storage Space\n",
    "        volPart = height * depth * width\n",
    "        numOfBins = round(ohInven / (volBin // volPart), 2)            ###  Returns Fraction. \n",
    "\n",
    "        return numOfBins\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function for Storage Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStorage(zone, pdesc, depth, width, height, ohInven):\n",
    "    # Initialize the empty Variables\n",
    "    storageType = \"\"\n",
    "    subStorage = \"\"\n",
    "\n",
    "    isSpec, storageType, subStorage, raw_bin_dim = utils.getSpecialityStorage(pdesc, depth, width, height)\n",
    "\n",
    "    if not isSpec: \n",
    "        if (zone == \"Red Hot\") | (zone == \"Red\"):\n",
    "            storageType, subStorage, raw_bin_dim = utils.getRedHotStorage(depth, width, height)\n",
    "        elif zone == \"Orange\":\n",
    "            storageType, subStorage, raw_bin_dim = utils.getOrangeStorage(depth, width, height)\n",
    "        elif zone == \"Yellow\":\n",
    "            storageType, subStorage, raw_bin_dim = utils.getYellowStorage(depth, width, height)\n",
    "        elif zone == \"Green\":   \n",
    "            storageType, subStorage, raw_bin_dim = utils.getGreenStorage(depth, width, height)\n",
    "        elif zone == \"Blue\":\n",
    "            storageType, subStorage, raw_bin_dim = utils.getBlueStorage(depth, width, height)\n",
    "\n",
    "    numOfBins = getNumOfBin(depth, width, height, raw_bin_dim, ohInven)\n",
    "    binDim =  raw_bin_dim.split('_')[0] + raw_bin_dim.split('_')[3] + raw_bin_dim.split('_')[2] + raw_bin_dim.split('_')[1]\n",
    "    \n",
    "\n",
    "    return storageType, subStorage, binDim, numOfBins # Return the Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the Storage Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_Main.shape[0]):\n",
    "    # Set the Dimensions of the Data into Variables\n",
    "    depth = df_Main.loc[i, \"Depth\"]\n",
    "    height = df_Main.loc[i, \"Height\"]\n",
    "    width = df_Main.loc[i, \"Width\"]\n",
    "\n",
    "    zone = df_Main.loc[i, \"Zone\"]\n",
    "    pdesc = df_Main.loc[i, \"Part Desc.\"]\n",
    "    ohInven = df_Main.loc[i, \"OH Inventory\"]\n",
    "\n",
    "    # If any dimension is zero, set empty Storage\n",
    "    if df_Main.loc[i, \"0Dimensions\"] == True:\n",
    "        df_Main.loc[i, \"StorageType\"] = \"\"\n",
    "        df_Main.loc[i, \"SubStorage\"] = \"\"\n",
    "        continue\n",
    "\n",
    "    # Set Storage of the Parts\n",
    "    df_Main.loc[i, \"StorageType\"], df_Main.loc[i, \"SubStorage\"], df_Main.loc[i, \"Bin Type\"], df_Main.loc[i, \"Num. Storage Required\"] = getStorage(zone, pdesc, depth, width, height, ohInven)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ^ Tire Storage Calculation\n",
    "# TODO: CLARIFY the Calculation of Tire Carousel Model Selection Based on Percentage \n",
    "## * ASSUMPTION:  If 50% of Tires Have 33-inch or More Diameter, Assign Large-Storage (72-width carousel)\n",
    "## * ELSE,  For 28-inch or less, and,  between 28-33 inches, assign standard carrousel (48-width carousel) \n",
    "# & df_Main.loc[df_Main['StorageType'] == 'Tire Specialty Storage', 'SubStorage'] \n",
    "carousel_model = '72-inch Wide' if df_Main[df_Main['StorageType'] == 'Tire Specialty Storage'][df_Main['SubStorage'] == '>33-inches Wide'].shape[0] / df_Main[df_Main['StorageType'] == 'Tire Specialty Storage'].shape[0] >= TIRE_PERCENT1 else '48-inch Wide'\n",
    "#carousel_width = '72' if df_Main[df_Main['StorageType'] == 'Tire Specialty Storage'][df_Main['SubStorage'] == '>33-inches Wide'].shape[0] / df_Main[df_Main['StorageType'] == 'Tire Specialty Storage'].shape[0] >= TIRE_PERCENT1 else '48'\n",
    "for tirePN in df_Main.loc[df_Main['StorageType'] == 'Tire Specialty Storage', \"Part#\"]:\n",
    "    df_Main.loc[(df_Main['Part#'] == tirePN), \"Num. Storage Required\"] = getNumOfBin(df_Main.loc[(df_Main['Part#'] == tirePN), \"Depth\"].values[0], df_Main.loc[(df_Main['Part#'] == tirePN), \"Width\"].values[0], df_Main.loc[(df_Main['Part#'] == tirePN), \"Height\"].values[0], f\"{df_Main.loc[(df_Main['Part#'] == tirePN), \"Height\"].values[0]}_{df_Main.loc[(df_Main['Part#'] == tirePN), \"Depth\"].values[0]}_{carousel_width}\", df_Main.loc[(df_Main['Part#'] == tirePN), \"OH Inventory\"].values[0])\n",
    "    df_Main.loc[(df_Main['Part#'] == tirePN), \"StorageType\"] += carousel_model + \" Carousel\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_df(df_Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Main.to_excel('FinalDataset.xlsx', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Main[\"StorageType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Main[(df_Main[\"0Dimensions\"] == True) & (df_Main[\"StorageType\"] == \"\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
