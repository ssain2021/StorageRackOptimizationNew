{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################  Storage_Optimization.ipynb  ####################################\n",
    "# Author: Sukhendu Sain\n",
    "# Description: Main file of codebase. Houses main code\n",
    "# Data: 23-Nov-2024\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries, Utils, and Config Files\n",
    "import utils\n",
    "from config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "import matplotlib.pyplot as plt\n",
    "# import importlib\n",
    "# importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config - Parameters/Other Variables/File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Files Path ##\n",
    "ROOT_FILE_PATH = '\\\\'.join(os.getcwd().split('\\\\')[:-1])\n",
    "\n",
    "AKINS_FOMO_FILE_PATH = os.path.join(ROOT_FILE_PATH, r\"Data&Files\\AKINS FoMoCo_Piece_Sales_112222_YTD.xlsx\")\n",
    "GPARTS_FILE_PATH = os.path.join(ROOT_FILE_PATH, r\"Data&Files\\GPARTS Part Measures.xlsx\")\n",
    "WHOLESALE_FILE_PATH = os.path.join(ROOT_FILE_PATH, r\"Data&Files\\Wholesale JAN_Oct_Parts_Ranking_Counter_Invoices_All_Brands.xlsx\")\n",
    "SERVICE_FILE_PATH = os.path.join(ROOT_FILE_PATH, r\"Data&Files\\Service JAN_Oct_Parts_Ranking_ROs_All_Brands.xlsx\")\n",
    "COUNTERPAD_FILE_PATH = os.path.join(ROOT_FILE_PATH, r\"Data&Files\\Counter_Pad_11142024.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "## Variables\n",
    "print_df_after_import = True\n",
    "print_df_data_analyse = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (AKINS FoMoCo_Piece_Sales_112222_YTD.xlsx) into Dataframe\n",
    "df_Akins = utils.read_excel(AKINS_FOMO_FILE_PATH)\n",
    "df_Akins['Part#'] = df_Akins['Part#'].apply(lambda a: \"\".join(str(a).split('-')))\n",
    "if print_df_after_import: utils.print_df(df_Akins, 200) # Print the Dataframe\n",
    "# ~1-2secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (GPARTS Part Measures.xlsx) into Dataframe\n",
    "df_Gparts = utils.read_excel(GPARTS_FILE_PATH)\n",
    "if print_df_after_import: utils.print_df(df_Gparts) # Print the Dataframe\n",
    "# ~50-60secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Wholesale JAN_Oct_Parts_Ranking_Counter_Invoices_All_Brands.xlsx) into Dataframe\n",
    "df_Wholesale = utils.read_excel(WHOLESALE_FILE_PATH)\n",
    "\n",
    "# Clean the Wholesale Dataframe\n",
    "df_Wholesale = df_Wholesale.drop(columns=[col for col in df_Wholesale.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Wholesale = df_Wholesale[(df_Wholesale['Vendor'] == 'FOR') | (df_Wholesale['Vendor'] == 'CHR')].reset_index()\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Wholesale) # Print the Dataframe\n",
    "# ~15secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Service JAN_Oct_Parts_Ranking_ROs_All_Brands.xlsx) into Dataframe\n",
    "df_Service = utils.read_excel(SERVICE_FILE_PATH)\n",
    "\n",
    "# Clean the Service Dataframe\n",
    "df_Service = df_Service.drop(columns=[col for col in df_Service.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Service = df_Service[(df_Service['Vendor'] == 'FOR') | (df_Service['Vendor'] == 'CHR')].reset_index()\n",
    "df_Service['Qty Sold'] = df_Service['Qty Sold'].astype(int)\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Service, 100) # Print the Dataframe\n",
    "# ~5-6secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Counter Pad) into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Akins File Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort 'Sold Pcs' Column Descending\n",
    "df_Akins = df_Akins.sort_values('Sold Pcs ', ascending=False)\n",
    "if print_df_data_analyse: utils.print_df(df_Akins, 100) # Print the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Sold Pcs' for each unique 'Part Desc.'\n",
    "part_type_sold_sum = df_Akins.groupby('Description')['Sold Pcs '].sum().reset_index()\n",
    "part_type_sold_sum.columns = ['Part Desc.', 'Total Sold Pcs.']\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_sold_sum = part_type_sold_sum.sort_values('Total Sold Pcs.', ascending=False)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_sold_sum, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize above part_type_sold_sum using Bar, One Fig of Top 10 Most Sold Part Types and One for Top 50\n",
    "top_10 = part_type_sold_sum.head(10)\n",
    "top_50 = part_type_sold_sum.head(50)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Sold Pieces (Akins)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Sold Pcs.']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create the bar chart for Top 50\n",
    "plt.figure(figsize=(9, 6))  # Set the figure size\n",
    "plt.bar(top_50['Part Desc.'], top_50['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 50 Part Types by Total Sold Pieces (Akins)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='x', linestyle='--', alpha=1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GParts File Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyze 'Active' Column of GParts\n",
    "total_rows = df_Gparts.shape[0]\n",
    "active = df_Gparts[df_Gparts[\"Is Active?\"] == 'Yes'].shape[0]\n",
    "active_percent = ( df_Gparts[df_Gparts[\"Is Active?\"] == 'Yes'].shape[0]/total_rows ) * 100\n",
    "\n",
    "# Print the Counts/Percentage\n",
    "print(f\"Active Parts: {active}; Active Percentage: {active_percent}%\")\n",
    "print(f\"Not Active Parts: {total_rows - active}; Not Active Percentage: {100 - active_percent}%\")\n",
    "\n",
    "# Visualize\n",
    "labels = ['Active', 'Not Active'] # Create labels and sizes for the pie chart\n",
    "sizes = [active_percent, 100 - active_percent]\n",
    "\n",
    "plt.figure(figsize=(10, 8)) # Create the pie chart\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, textprops={'fontsize': 23})\n",
    "\n",
    "plt.show() # Show the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Rows with 0 in either Dimensions\n",
    "# Depth (Column Here) = Length (In Docs)\n",
    "\n",
    "# Count no. of Rows with 0 in either Dimensions; no_all share count with other 3\n",
    "no_depth = df_Gparts[df_Gparts[\"Prod Att - Length\"] == 0].shape[0]\n",
    "no_width = df_Gparts[df_Gparts[\"Prod Att- Width\"] == 0].shape[0]\n",
    "no_height = df_Gparts[df_Gparts[\"Prod Att - Height\"] == 0].shape[0]\n",
    "no_all = df_Gparts[(df_Gparts[\"Prod Att - Height\"] == 0) & (df_Gparts[\"Prod Att- Width\"] == 0) & (df_Gparts[\"Prod Att - Length\"] == 0)].shape[0]\n",
    "\n",
    "# Calculate percentages\n",
    "total_rows = df_Gparts.shape[0]\n",
    "percent_no_depth = (no_depth / total_rows) * 100\n",
    "percent_no_width = (no_width / total_rows) * 100\n",
    "percent_no_height = (no_height / total_rows) * 100\n",
    "percent_no_all = (no_all / total_rows) * 100\n",
    "\n",
    "# Count 'Active' Parts having No Dimensions and Dimensions\n",
    "No_Dim_Active = df_Gparts[(df_Gparts[\"Prod Att - Height\"] == 0) & (df_Gparts[\"Is Active?\"] == 'Yes')].shape[0]\n",
    "No_Dim_Not_Active = df_Gparts[(df_Gparts[\"Prod Att - Height\"] == 0) & (df_Gparts[\"Is Active?\"] == 'No')].shape[0]\n",
    "No_Dim_Active_Percent = (No_Dim_Active/no_all) * 100\n",
    "No_Dim_Not_Active_Percent = (No_Dim_Not_Active/no_all) * 100\n",
    "With_Dim_Active = df_Gparts[(df_Gparts[\"Prod Att - Height\"] != 0) & (df_Gparts[\"Is Active?\"] == 'Yes')].shape[0]\n",
    "With_Dim_Not_Active = df_Gparts[(df_Gparts[\"Prod Att - Height\"] != 0) & (df_Gparts[\"Is Active?\"] == 'No')].shape[0]\n",
    "With_Dim_Active_Percent = (With_Dim_Active/(total_rows - no_all)) * 100\n",
    "With_Dim_Not_Active_Percent = (With_Dim_Not_Active/(total_rows - no_all)) * 100\n",
    "\n",
    "# Print the Counts/Percentages\n",
    "print(f\"No Length/Depth: {round(no_depth/total_rows*100, 2)}%; No Width: {round(no_width/total_rows*100, 2)}%; No Height: {round(no_height/total_rows*100, 2)}%; No Dimensions: {round(percent_no_all, 2)}%;\")\n",
    "print(f\"Active Parts of No Dimensions: {No_Dim_Active}; Percentage with respect to Parts without Dims: {round(No_Dim_Active_Percent, 2)}%\")\n",
    "print(f\"Not Active Parts of No Dimensions: {No_Dim_Not_Active}; Percentage with respect to Parts without Dims: {round(No_Dim_Not_Active_Percent, 2)}%\")\n",
    "print(f\"Active Parts with Dimensions: {With_Dim_Active}; Percentage with respect to Parts with Dims: {round(With_Dim_Active_Percent, 2)}%\")\n",
    "print(f\"Not Active Parts with Dimensions: {With_Dim_Not_Active}; Percentage with respect to Parts with Dims: {round(With_Dim_Not_Active_Percent, 2)}%\")\n",
    "\n",
    "# Here we find out that a row, if containing 0 in 1 dimension, has 0 in all, or\n",
    "# A row has either all or none dimensions\n",
    "# 16% of Rows has 0 Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "labels = ['Active', 'Not Active'] # Create labels and sizes for the pie chart\n",
    "sizes = [No_Dim_Active_Percent, No_Dim_Not_Active_Percent]\n",
    "\n",
    "plt.figure(figsize=(10, 8)) # Create the pie chart\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, textprops={'fontsize': 20})\n",
    "\n",
    "plt.show() # Show the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize above No Dimensions Data\n",
    "\n",
    "# Create the bar graph\n",
    "plt.figure(figsize=(10, 6)) \n",
    "bars = ['Total Rows', 'No Length/Depth', 'No Width', 'No Height']\n",
    "heights = [100, percent_no_depth, percent_no_width, percent_no_height]\n",
    "\n",
    "plt.bar(bars, heights)\n",
    "plt.title(f'Distribution of Rows with No Dimensions', fontsize=16)\n",
    "plt.ylabel('Percentage of Rows')\n",
    "plt.xticks(rotation=45, fontsize=16)\n",
    "\n",
    "# Add labels to each bar\n",
    "for i, v in enumerate(heights):\n",
    "    plt.text(i, v, str(round(v, 2)) + '%', ha='center', va='bottom')\n",
    "\n",
    "# Show the legend and display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize everything Analyzed above in a single Stacked Bar Chart\n",
    "\n",
    "categories = ['Total Rows', 'Dimensional Rows', 'No Dimensional Rows']\n",
    "values1 = [active, With_Dim_Active, No_Dim_Active]\n",
    "values2 = [total_rows - active, With_Dim_Not_Active, No_Dim_Not_Active]\n",
    "\n",
    "# Create figure and axis objects\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "ax.bar(categories, values1, label='Active', width = 0.3)\n",
    "ax.bar(categories, values2, bottom=values1, label='Not Active', width = 0.3)\n",
    "\n",
    "for i, v in enumerate([total_rows, With_Dim_Active+With_Dim_Not_Active, No_Dim_Active+No_Dim_Not_Active]):\n",
    "    plt.text(i, v, f'Total: {str(v)}', ha='center', va='bottom')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Bar Chart of Active and Non-Active Parts (GParts)')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_yticks(np.linspace(0, 231045, 20))  # Set more ticks on y-axis\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=1)\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wholesale Files Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort 'Sold' Column Descending\n",
    "df_Wholesale = df_Wholesale.sort_values('Sold', ascending=False)\n",
    "if print_df_data_analyse: utils.print_df(df_Wholesale, 100) # Print the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the number of negative sold pcs.\n",
    "neg_sold_count = df_Wholesale[df_Wholesale['Sold'] < 0].shape[0]\n",
    "print(f\"Number of Negative Sold Values: {neg_sold_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Gross Profit' for each unique 'Part Desc.'\n",
    "part_type_profit_sum = df_Wholesale.groupby('Description')['Gross Profit'].sum().reset_index()\n",
    "part_type_profit_sum.columns = ['Part Desc.', 'Total Gross Profit']\n",
    "part_type_profit_sum['Total Gross Profit'] = pd.to_numeric(part_type_profit_sum['Total Gross Profit'], errors='coerce').round()\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_profit_sum = part_type_profit_sum.sort_values('Total Gross Profit', ascending=False)\n",
    "part_type_profit_sum['Total Gross Profit'] = part_type_profit_sum['Total Gross Profit'].round(-1)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_profit_sum, 5)\n",
    "\n",
    "# Visualize using Bar of Top 10\n",
    "top_10 = part_type_profit_sum.head(10)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Gross Profit'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Gross Profit (Wholesale)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Gross Profit', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Gross Profit']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Sold' for each unique 'Part Desc.'\n",
    "part_type_sold_sum = df_Wholesale.groupby('Description')['Sold'].sum().reset_index()\n",
    "part_type_sold_sum.columns = ['Part Desc.', 'Total Sold Pcs.']\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_sold_sum = part_type_sold_sum.sort_values('Total Sold Pcs.', ascending=False)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_sold_sum, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize above part_type_sold_sum using Bar, One Fig of Top 10 Most Sold Part Types and One for Top 50\n",
    "top_10 = part_type_sold_sum.head(10)\n",
    "top_50 = part_type_sold_sum.head(50)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Sold Pieces (Wholesale)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Sold Pcs.']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create the bar chart for Top 50\n",
    "plt.figure(figsize=(9, 6))  # Set the figure size\n",
    "plt.bar(top_50['Part Desc.'], top_50['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 50 Part Types by Total Sold Pieces (Wholesale)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='x', linestyle='--', alpha=1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service File Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort 'Qty Sold' Column Descending\n",
    "df_Service = df_Service.sort_values('Qty Sold', ascending=False)\n",
    "if print_df_data_analyse: utils.print_df(df_Service, 100) # Print the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the number of negative sold pcs.\n",
    "neg_sold_count = df_Service[df_Service['Qty Sold'].astype(int) < 0].shape[0]\n",
    "print(f\"Number of Negative Sold Values: {neg_sold_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Gross Profit' for each unique 'Part Desc.'\n",
    "part_type_profit_sum = df_Service.groupby('Description')['Gross Profit'].sum().reset_index()\n",
    "part_type_profit_sum.columns = ['Part Desc.', 'Total Gross Profit']\n",
    "part_type_profit_sum['Total Gross Profit'] = pd.to_numeric(part_type_profit_sum['Total Gross Profit'], errors='coerce').round()\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_profit_sum = part_type_profit_sum.sort_values('Total Gross Profit', ascending=False)\n",
    "part_type_profit_sum['Total Gross Profit'] = part_type_profit_sum['Total Gross Profit'].round(-1)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_profit_sum, 5)\n",
    "\n",
    "# Visualize using Bar of Top 10\n",
    "top_10 = part_type_profit_sum.head(10)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Gross Profit'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Gross Profit (Service)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Gross Profit', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Gross Profit']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Sold' for each unique 'Part Desc.'\n",
    "part_type_sold_sum = df_Service.groupby('Description')['Qty Sold'].sum().reset_index()\n",
    "part_type_sold_sum.columns = ['Part Desc.', 'Total Sold Pcs.']\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_sold_sum = part_type_sold_sum.sort_values('Total Sold Pcs.', ascending=False)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_sold_sum, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize above part_type_sold_sum using Bar, One Fig of Top 10 Most Sold Part Types and One for Top 50\n",
    "top_10 = part_type_sold_sum.head(10)\n",
    "top_50 = part_type_sold_sum.head(50)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Sold Pieces (Service)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Sold Pcs.']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create the bar chart for Top 50\n",
    "plt.figure(figsize=(9, 6))  # Set the figure size\n",
    "plt.bar(top_50['Part Desc.'], top_50['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 50 Part Types by Total Sold Pieces (Service)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='x', linestyle='--', alpha=1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Number of Matching Part Numbers in each of the Dataframe\n",
    "\n",
    "# The Dataframes to match\n",
    "all_dfs = [df_Akins, df_Gparts]\n",
    "\n",
    "# Part# Column Name of each DF\n",
    "part_number_columns = ['Part#', 'Svc Part Number']\n",
    "\n",
    "# Find common part numbers\n",
    "common_part_numbers = set(all_dfs[0][part_number_columns[0]])\n",
    "for i in range(1, len(all_dfs)):\n",
    "    common_part_numbers &= set(all_dfs[i][part_number_columns[i]])\n",
    "\n",
    "print(f\"Part numbers common to all DataFrames: {len(common_part_numbers)}\")\n",
    "#if print_df_data_analyse: utils.print_df(df_Wholesale[df_Wholesale[\"Part Number\"].isin(common_part_numbers)], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing & Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 11 elements, new values have 10 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     main_list\u001b[38;5;241m.\u001b[39mappend([pn, pt, ac, s, ld, w, h, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     22\u001b[0m df_Main \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(main_list)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mdf_Main\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPart#\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPart Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSold\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeight\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStorageType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubStorage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNum. Storage Required\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     25\u001b[0m utils\u001b[38;5;241m.\u001b[39mprint_df(df_Main)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 11 elements, new values have 10 elements"
     ]
    }
   ],
   "source": [
    "## Make a Big Final Dataframe\n",
    "# It will have the Columns - 'Part Number', 'Part Type', 'Active', 'Sold (Pcs.)', 'Length/Depth', 'Width', 'Height', 'Zone', 'Storage Type', 'Sub Storage', 'Number of Storage needed'\n",
    "# It will have all the rows with common part nos. from all 4 Files, having Appropriate Sold Pcs. Values, and Dimensions\n",
    "\n",
    "main_list = []\n",
    "\n",
    "gParts_PartNos = set(df_Gparts['Svc Part Number'])\n",
    "\n",
    "common_part_numbers = gParts_PartNos & set(df_Akins['Part#'])\n",
    "for pn, pt, ac, s, ld, w, h in zip(common_part_numbers, df_Gparts[\"Svc Part Number Description\"], df_Gparts['Is Active?'], df_Akins['Sold Pcs '], df_Gparts['Prod Att - Length'], df_Gparts['Prod Att- Width'], df_Gparts['Prod Att - Height']):\n",
    "    main_list.append([pn, pt, ac, s, ld, w, h, \"\", \"\", \"\", \"\"])\n",
    "\n",
    "common_part_numbers = gParts_PartNos & set(df_Wholesale['Part Number'])\n",
    "for pn, pt, ac, s, ld, w, h in zip(common_part_numbers, df_Gparts[\"Svc Part Number Description\"], df_Gparts['Is Active?'], df_Wholesale['Sold'], df_Gparts['Prod Att - Length'], df_Gparts['Prod Att- Width'], df_Gparts['Prod Att - Height']):\n",
    "    main_list.append([pn, pt, ac, s, ld, w, h, \"\", \"\", \"\", \"\"])\n",
    "\n",
    "\n",
    "common_part_numbers = gParts_PartNos & set(df_Service['* indicates a superseded part\\nPart Number'])\n",
    "for pn, pt, ac, s, ld, w, h in zip(common_part_numbers, df_Gparts[\"Svc Part Number Description\"], df_Gparts['Is Active?'], df_Service['Qty Sold'], df_Gparts['Prod Att - Length'], df_Gparts['Prod Att- Width'], df_Gparts['Prod Att - Height']):\n",
    "    main_list.append([pn, pt, ac, s, ld, w, h, \"\", \"\", \"\", \"\"])\n",
    "\n",
    "df_Main = pd.DataFrame(main_list)\n",
    "df_Main.columns = ['Part#', 'Part Type', 'Sold', 'Depth', 'Width', 'Height', 'Zone', 'StorageType', 'SubStorage', 'Num. Storage Required']\n",
    "\n",
    "utils.print_df(df_Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "sum = 0\n",
    "totalSoldPCs = int(df_Wholesale[\"Total Sold\"].sum())\n",
    "print(sum, totalSoldPCs)\n",
    "for i in range(df_Wholesale.shape[0]):\n",
    "    zone = \"\"\n",
    "    if sum/totalSoldPCs <= 0.2:\n",
    "        zone = \"Red Hot Zone\"\n",
    "    if sum/totalSoldPCs > 0.2 and sum/totalSoldPCs <= 0.4:\n",
    "        zone = \"Orange Zone\"\n",
    "    if sum/totalSoldPCs > 0.4 and sum/totalSoldPCs <= 0.6:\n",
    "        zone = \"Yellow Zone\"\n",
    "    if sum/totalSoldPCs > 0.6 and sum/totalSoldPCs <= 0.8:\n",
    "        zone = \"Green Zone\"\n",
    "    if sum/totalSoldPCs > 0.8:\n",
    "        zone = \"Blue Zone\"\n",
    "    data.append([df_Wholesale[\"Part Number\"].iloc[i], zone, sum])\n",
    "    sum = sum + df_Wholesale[\"Total Sold\"].iloc[i]\n",
    "df_zones = pd.DataFrame(data)\n",
    "utils.print_df(df_zones,None)\n",
    "\n",
    "with open(\"htt.txt\", \"w\") as f:\n",
    "    f.write(df_zones.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
