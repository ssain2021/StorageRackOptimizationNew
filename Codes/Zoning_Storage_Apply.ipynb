{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################  Storage_Optimization.ipynb  ####################################\n",
    "# Author: Sukhendu Sain\n",
    "# Description: Main file of codebase. Houses main code\n",
    "# Data: 23-Nov-2024\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries, Utils, and Config Files\n",
    "import utils\n",
    "from config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "import matplotlib.pyplot as plt\n",
    "# import importlib\n",
    "# importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (AKINS FoMoCo_Piece_Sales_112222_YTD.xlsx) into Dataframe\n",
    "df_Akins = utils.read_excel(AKINS_FOMO_FILE_PATH)\n",
    "df_Akins['Part#'] = df_Akins['Part#'].apply(lambda a: \"\".join(str(a).split('-')))\n",
    "if print_df_after_import: utils.print_df(df_Akins, 200) # Print the Dataframe\n",
    "# ~1-2secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (GPARTS Part Measures.xlsx) into Dataframe\n",
    "df_Gparts = utils.read_excel(GPARTS_FILE_PATH)\n",
    "if print_df_after_import: utils.print_df(df_Gparts) # Print the Dataframe\n",
    "# ~50-60secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Wholesale JAN_Oct_Parts_Ranking_Counter_Invoices_All_Brands.xlsx) into Dataframe\n",
    "df_Wholesale = utils.read_excel(WHOLESALE_FILE_PATH)\n",
    "\n",
    "# Clean the Wholesale Dataframe\n",
    "df_Wholesale['Description'] = df_Wholesale['Description'].astype(str)\n",
    "df_Wholesale = df_Wholesale.drop(columns=[col for col in df_Wholesale.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Wholesale = df_Wholesale[(df_Wholesale['Vendor'] == 'FOR') | (df_Wholesale['Vendor'] == 'CHR')].reset_index()\n",
    "df_Wholesale.loc[df_Wholesale['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Avg. Cost'] = df_Wholesale['Description'].apply(lambda x: [i for i in x.strip().split(\"      \")][-1])\n",
    "df_Wholesale.loc[df_Wholesale['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Description'] = df_Wholesale['Description'].apply(lambda x: \"     \".join([i for i in x.strip().split(\"      \")][:-1]))\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Wholesale) # Print the Dataframe\n",
    "# ~12-15secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Service JAN_Oct_Parts_Ranking_ROs_All_Brands.xlsx) into Dataframe\n",
    "df_Service = utils.read_excel(SERVICE_FILE_PATH)\n",
    "\n",
    "# Clean the Service Dataframe\n",
    "df_Service = df_Service.drop(columns=[col for col in df_Service.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Service = df_Service[(df_Service['Vendor'] == 'FOR') | (df_Service['Vendor'] == 'CHR')].reset_index()\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Service, 100) # Print the Dataframe\n",
    "# ~5-6secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Counter Pad) into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing & Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Big Final Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will have the Columns - 'Part Number', 'Part Desc.', 'Active', 'Sold (Pcs.)', '0Dimensions', 'Length/Depth', 'Width', 'Height', 'Zone', 'Storage Type', 'Sub Storage', 'Number of Storage needed'\n",
    "# It will have all the rows with common part nos. from all 4 Files, having Appropriate Sold Pcs. Values, and Dimensions\n",
    "\n",
    "main_list = []\n",
    "\n",
    "gParts_PartNos = set(df_Gparts['Svc Part Number'])\n",
    "\n",
    "common_part_numbers = gParts_PartNos & set(df_Akins['Part#'])\n",
    "for pn, pddesc, ac, s, ld, w, h in zip(common_part_numbers, df_Gparts[\"Svc Part Number Description\"], df_Gparts['Is Active?'], df_Akins['Sold Pcs '], df_Gparts['Prod Att - Length'], df_Gparts['Prod Att- Width'], df_Gparts['Prod Att - Height']):\n",
    "    main_list.append([pn, pddesc, \"Akins\", ac, s, False, ld, w, h, \"\", \"\", \"\", \"\"])\n",
    "\n",
    "common_part_numbers = gParts_PartNos & set(df_Wholesale['Part Number'])\n",
    "for pn, pddesc, ac, s, ld, w, h in zip(common_part_numbers, df_Gparts[\"Svc Part Number Description\"], df_Gparts['Is Active?'], df_Wholesale['Sold'], df_Gparts['Prod Att - Length'], df_Gparts['Prod Att- Width'], df_Gparts['Prod Att - Height']):\n",
    "    main_list.append([pn, pddesc, \"Wholesale\", ac, s, False, ld, w, h, \"\", \"\", \"\", \"\"])\n",
    "\n",
    "\n",
    "common_part_numbers = gParts_PartNos & set(df_Service['* indicates a superseded part\\nPart Number'])\n",
    "for pn, pddesc, ac, s, ld, w, h in zip(common_part_numbers, df_Gparts[\"Svc Part Number Description\"], df_Gparts['Is Active?'], df_Service['Qty Sold'], df_Gparts['Prod Att - Length'], df_Gparts['Prod Att- Width'], df_Gparts['Prod Att - Height']):\n",
    "    main_list.append([pn, pddesc, \"Service\", ac, s, False, ld, w, h, \"\", \"\", \"\", \"\"])\n",
    "\n",
    "df_Main = pd.DataFrame(main_list)\n",
    "df_Main.columns = ['Part#', 'Part Desc.', 'DataSource', 'Active', 'Sold', '0Dimensions', 'Depth', 'Width', 'Height', 'Zone', 'StorageType', 'SubStorage', 'Num. Storage Required']\n",
    "df_Main = df_Main.sort_values('Sold', ascending=False).reset_index()\n",
    "df_Main[\"Zone\"] = df_Main[\"Zone\"].astype(str)\n",
    "df_Main.loc[(df_Main[\"Depth\"] == 0) | (df_Main[\"Height\"] == 0) | (df_Main[\"Width\"] == 0), \"0Dimensions\"] = True\n",
    "df_Main = df_Main[df_Main[\"0Dimensions\"] == False].reset_index()\n",
    "df_Main.drop(['index', 'level_0'], axis=1, inplace=True)\n",
    "\n",
    "utils.print_df(df_Main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Zoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main Function for Apply Zoning\n",
    "def Apply_Zoning(df_toBeZoned, Zones=['Red Hot', 'Orange', 'Yellow', 'Green', 'Blue'], thresMultiplier=0.2, soldColName='Sold', zoneColName='Zone'):\n",
    "    # Initialize Variables\n",
    "    sold_sum = 0 # Keep sum of all Sold until now in the current zone\n",
    "    threshold = thresMultiplier * df_toBeZoned[soldColName].sum() # Threshold of Sum of Sold of each Zone\n",
    "    zoneIndex = 0 # Current Zone Index\n",
    "    zoneStartIndex = 0 # Current Zone Start Index of the Data\n",
    "\n",
    "    # Main Loop\n",
    "    for ind in range(df_toBeZoned.shape[0]): # Loop through each Data\n",
    "        if sold_sum > threshold: # Check if the Sum exceeds the threshold\n",
    "            df_toBeZoned.loc[zoneStartIndex:ind, zoneColName] = Zones[zoneIndex] # Set all the Rows from Current zoneStartIndex to now the Current Zone\n",
    "            zoneStartIndex = ind # Set the zoneStartIndex for next zone to the End of current zone\n",
    "            zoneIndex = zoneIndex + 1 # Increment the Zone Index\n",
    "            sold_sum = 0 # Reset the Sold Sum when the current zone ends\n",
    "        else: \n",
    "            sold_sum = sold_sum + df_toBeZoned[soldColName].iloc[ind] # If not exceeding add Sold Sum to the Sold of the current row\n",
    "    df_toBeZoned.loc[df_toBeZoned[zoneColName] == \"\", zoneColName] = Zones[-1] #  Set all the leftoever empty zone Rows, to the Last Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the Apply_Zoning on df_Main\n",
    "Apply_Zoning(df_Main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check each Zones, number of Part Numbers and Sum of Sold of each of their Part Numbers\n",
    "df_Main.groupby('Zone')['Sold'].sum(), df_Main.groupby('Zone')['Sold'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Storage Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Storage Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStorage(zone, pdesc, depth, width, height):\n",
    "    # Initialize the empty Variables\n",
    "    storageType = \"\"\n",
    "    subStorage = \"\"\n",
    "\n",
    "    # For Specialty Items\n",
    "    \n",
    "\n",
    "    # For High Density Drawers: If a Zone is Red Hot and meets the maximum dimensions criterion\n",
    "    if (zone == \"Red Hot\") & (depth < 24) & (height < 6) & (width < 12):\n",
    "        storageType = \"High Density Drawers\" # Set Storage Type accordingly\n",
    "        if (width < 9): # If the depth is less than 9\n",
    "            subStorage = \"36\\\" Drawer - 4 Compart\"\n",
    "        if (width < 8):\n",
    "            subStorage = \"48\\\" Drawer - 6 Compart\"\n",
    "        if (width < 12):\n",
    "            subStorage = \"48\\\" Drawer - 4 Compart\"\n",
    "    elif (depth < 24) & (height < 15) & (width < 48): # For Clip Shelving:\n",
    "        storageType = \"Clip Shelving\" # Set Storage Type accordingly\n",
    "        if (depth < 12):  # If the depth is less than 12\n",
    "            subStorage = \"12\\\" Deep - \"\n",
    "        elif (depth < 18):\n",
    "            subStorage = \"18\\\" Deep - \"\n",
    "        elif (depth < 24):\n",
    "            subStorage = \"24\\\" Deep - \"\n",
    "        if (width < 36):\n",
    "            subStorage += \"36\\\" Wide Shelf\"\n",
    "        elif (width < 48):\n",
    "            subStorage += \"48\\\" Wide Shelf\"\n",
    "    elif (depth < 96) & (height > 12) & (width < 96): # For Bulk Shelving\n",
    "        storageType = \"Bulk Storage\" # Set Storage Type accordingly\n",
    "        if (depth < 24): # If the depth is less than 24\n",
    "            subStorage = \"24\\\" Deep - \"\n",
    "        elif (depth < 36):\n",
    "            subStorage = \"36\\\" Deep - \"\n",
    "        elif (depth < 42):\n",
    "            subStorage = \"42\\\" Deep - \"\n",
    "        elif (depth < 48):\n",
    "            subStorage = \"48\\\" Deep - \"\n",
    "        elif (depth < 72):\n",
    "            subStorage = \"72\\\" Deep - \"\n",
    "        elif (depth < 96):\n",
    "            subStorage = \"96\\\" Deep - \"\n",
    "        if (width < 48):\n",
    "            subStorage += \"48\\\" Wide Shelf\"\n",
    "        elif (width < 72):\n",
    "            subStorage += \"96\\\" Wide Shelf\"\n",
    "        elif (width < 96):\n",
    "            subStorage += \"96\\\" Wide Shelf\"\n",
    "\n",
    "    return storageType, subStorage # Return the Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the Storage Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_Main.shape[0]):\n",
    "    # Set the Dimensions of the Data into Variables\n",
    "    depth = df_Main.loc[i, \"Depth\"]\n",
    "    height = df_Main.loc[i, \"Height\"]\n",
    "    width = df_Main.loc[i, \"Width\"]\n",
    "\n",
    "    zone = df_Main.loc[i, \"Zone\"]\n",
    "    pdesc = df_Main.loc[i, \"Part Desc.\"]\n",
    "\n",
    "    # If any dimension is zero, set empty Storage\n",
    "    if df_Main.loc[i, \"0Dimensions\"] == True:\n",
    "        df_Main.loc[i, \"StorageType\"] = \"\"\n",
    "        df_Main.loc[i, \"SubStorage\"] = \"\"\n",
    "        continue\n",
    "\n",
    "    # Set Storage of the Parts\n",
    "    df_Main.loc[i, \"StorageType\"], df_Main.loc[i, \"SubStorage\"] = getStorage(zone, pdesc, depth, width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_df(df_Main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
