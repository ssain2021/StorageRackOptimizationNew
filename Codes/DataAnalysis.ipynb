{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################  Storage_Optimization.ipynb  ####################################\n",
    "# Author: Sukhendu Sain\n",
    "# Description: Analyse the Data\n",
    "# Data: 23-Nov-2024\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries, Utils, and Config Files\n",
    "import utils\n",
    "from config import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "import matplotlib.pyplot as plt\n",
    "# import importlib\n",
    "# importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (AKINS FoMoCo_Piece_Sales_112222_YTD.xlsx) into Dataframe\n",
    "df_Akins = utils.read_excel(AKINS_FOMO_FILE_PATH)\n",
    "df_Akins['Original Part#'] = df_Akins['Part#']\n",
    "df_Akins['Part#'] = df_Akins['Part#'].apply(lambda a: \"\".join(str(a).split('-')))\n",
    "if print_df_after_import: utils.print_df(df_Akins, 200) # Print the Dataframe\n",
    "# ~1-2secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (GPARTS Part Measures.xlsx) into Dataframe\n",
    "df_Gparts = utils.read_excel(GPARTS_FILE_PATH)\n",
    "if print_df_after_import: utils.print_df(df_Gparts) # Print the Dataframe\n",
    "# ~50-60secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Wholesale JAN_Oct_Parts_Ranking_Counter_Invoices_All_Brands.xlsx) into Dataframe\n",
    "df_Wholesale = utils.read_excel(WHOLESALE_FILE_PATH)\n",
    "\n",
    "# Clean the Wholesale Dataframe\n",
    "df_Wholesale['Description'] = df_Wholesale['Description'].astype(str)\n",
    "df_Wholesale = df_Wholesale.drop(columns=[col for col in df_Wholesale.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Wholesale = df_Wholesale[(df_Wholesale['Vendor'] == 'FOR') | (df_Wholesale['Vendor'] == 'CHR')].reset_index()\n",
    "df_Wholesale.loc[df_Wholesale['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Avg. Cost'] = df_Wholesale['Description'].apply(lambda x: [i for i in x.strip().split(\"      \")][-1])\n",
    "df_Wholesale.loc[df_Wholesale['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Description'] = df_Wholesale['Description'].apply(lambda x: \"     \".join([i for i in x.strip().split(\"      \")][:-1]))\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Wholesale, 14900) # Print the Dataframe\n",
    "# ~12-15secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Service JAN_Oct_Parts_Ranking_ROs_All_Brands.xlsx) into Dataframe\n",
    "df_Service = utils.read_excel(SERVICE_FILE_PATH)\n",
    "\n",
    "# Clean the Service Dataframe\n",
    "df_Service['Description'] = df_Service['Description'].astype(str)\n",
    "df_Service = df_Service.drop(columns=[col for col in df_Service.columns if 'Unnamed' in col], inplace=False)\n",
    "df_Service = df_Service[(df_Service['Vendor'] == 'FOR') | (df_Service['Vendor'] == 'CHR')].reset_index()\n",
    "df_Service.loc[df_Service['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Avg. Cost'] = df_Service['Description'].apply(lambda x: [i for i in x.strip().split(\"      \")][-1])\n",
    "df_Service.loc[df_Service['Description'].apply(lambda x: len(x.split(\"      \")) > 1), 'Description'] = df_Service['Description'].apply(lambda x: \"     \".join([i for i in x.strip().split(\"      \")][:-1]))\n",
    "#df_Service.loc[df_Service['Qty Sold'].apply(lambda x: len(str(x).split(\"      \")) > 1), 'Dollars Sold'] = df_Service['Qty Sold'].apply(lambda x: [i for i in str(x).strip().split(\"      \")][-1])\n",
    "#df_Service.loc[df_Service['Qty Sold'].apply(lambda x: len(str(x).split(\"      \")) > 1), 'Qty Sold'] = df_Service['Qty Sold'].apply(lambda x: \"     \".join([i for i in str(x).strip().split(\"      \")][:-1]))\n",
    "\n",
    "if print_df_after_import: utils.print_df(df_Service, 100) # Print the Dataframe\n",
    "# ~5-6secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read FILE:: (Counter Pad) into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Akins File Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort 'Sold Pcs' Column Descending\n",
    "df_Akins = df_Akins.sort_values('Sold Pcs ', ascending=False)\n",
    "if print_df_data_analyse: utils.print_df(df_Akins, 100) # Print the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Sold Pcs' for each unique 'Part Desc.'\n",
    "part_type_sold_sum = df_Akins.groupby('Description')['Sold Pcs '].sum().reset_index()\n",
    "part_type_sold_sum.columns = ['Part Desc.', 'Total Sold Pcs.']\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_sold_sum = part_type_sold_sum.sort_values('Total Sold Pcs.', ascending=False)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_sold_sum, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize above part_type_sold_sum using Bar, One Fig of Top 10 Most Sold Part Types and One for Top 50\n",
    "top_10 = part_type_sold_sum.head(10)\n",
    "top_50 = part_type_sold_sum.head(50)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Sold Pieces (Akins)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Sold Pcs.']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create the bar chart for Top 50\n",
    "plt.figure(figsize=(9, 6))  # Set the figure size\n",
    "plt.bar(top_50['Part Desc.'], top_50['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 50 Part Types by Total Sold Pieces (Akins)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='x', linestyle='--', alpha=1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GParts File Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyze 'Active' Column of GParts\n",
    "total_rows = df_Gparts.shape[0]\n",
    "active = df_Gparts[df_Gparts[\"Is Active?\"] == 'Yes'].shape[0]\n",
    "active_percent = ( df_Gparts[df_Gparts[\"Is Active?\"] == 'Yes'].shape[0]/total_rows ) * 100\n",
    "\n",
    "# Print the Counts/Percentage\n",
    "print(f\"Active Parts: {active}; Active Percentage: {active_percent}%\")\n",
    "print(f\"Not Active Parts: {total_rows - active}; Not Active Percentage: {100 - active_percent}%\")\n",
    "\n",
    "# Visualize\n",
    "labels = ['Active', 'Not Active'] # Create labels and sizes for the pie chart\n",
    "sizes = [active_percent, 100 - active_percent]\n",
    "\n",
    "plt.figure(figsize=(10, 8)) # Create the pie chart\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, textprops={'fontsize': 23})\n",
    "\n",
    "plt.show() # Show the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Rows with 0 in either Dimensions\n",
    "# Depth (Column Here) = Length (In Docs)\n",
    "\n",
    "# Count no. of Rows with 0 in either Dimensions; no_all share count with other 3\n",
    "no_depth = df_Gparts[df_Gparts[\"Prod Att - Length\"] == 0].shape[0]\n",
    "no_width = df_Gparts[df_Gparts[\"Prod Att- Width\"] == 0].shape[0]\n",
    "no_height = df_Gparts[df_Gparts[\"Prod Att - Height\"] == 0].shape[0]\n",
    "no_all = df_Gparts[(df_Gparts[\"Prod Att - Height\"] == 0) & (df_Gparts[\"Prod Att- Width\"] == 0) & (df_Gparts[\"Prod Att - Length\"] == 0)].shape[0]\n",
    "\n",
    "# Calculate percentages\n",
    "total_rows = df_Gparts.shape[0]\n",
    "percent_no_depth = (no_depth / total_rows) * 100\n",
    "percent_no_width = (no_width / total_rows) * 100\n",
    "percent_no_height = (no_height / total_rows) * 100\n",
    "percent_no_all = (no_all / total_rows) * 100\n",
    "\n",
    "# Count 'Active' Parts having No Dimensions and Dimensions\n",
    "No_Dim_Active = df_Gparts[(df_Gparts[\"Prod Att - Height\"] == 0) & (df_Gparts[\"Is Active?\"] == 'Yes')].shape[0]\n",
    "No_Dim_Not_Active = df_Gparts[(df_Gparts[\"Prod Att - Height\"] == 0) & (df_Gparts[\"Is Active?\"] == 'No')].shape[0]\n",
    "No_Dim_Active_Percent = (No_Dim_Active/no_all) * 100\n",
    "No_Dim_Not_Active_Percent = (No_Dim_Not_Active/no_all) * 100\n",
    "With_Dim_Active = df_Gparts[(df_Gparts[\"Prod Att - Height\"] != 0) & (df_Gparts[\"Is Active?\"] == 'Yes')].shape[0]\n",
    "With_Dim_Not_Active = df_Gparts[(df_Gparts[\"Prod Att - Height\"] != 0) & (df_Gparts[\"Is Active?\"] == 'No')].shape[0]\n",
    "With_Dim_Active_Percent = (With_Dim_Active/(total_rows - no_all)) * 100\n",
    "With_Dim_Not_Active_Percent = (With_Dim_Not_Active/(total_rows - no_all)) * 100\n",
    "\n",
    "# Print the Counts/Percentages\n",
    "print(f\"No Length/Depth: {round(no_depth/total_rows*100, 2)}%; No Width: {round(no_width/total_rows*100, 2)}%; No Height: {round(no_height/total_rows*100, 2)}%; No Dimensions: {round(percent_no_all, 2)}%;\")\n",
    "print(f\"Active Parts of No Dimensions: {No_Dim_Active}; Percentage with respect to Parts without Dims: {round(No_Dim_Active_Percent, 2)}%\")\n",
    "print(f\"Not Active Parts of No Dimensions: {No_Dim_Not_Active}; Percentage with respect to Parts without Dims: {round(No_Dim_Not_Active_Percent, 2)}%\")\n",
    "print(f\"Active Parts with Dimensions: {With_Dim_Active}; Percentage with respect to Parts with Dims: {round(With_Dim_Active_Percent, 2)}%\")\n",
    "print(f\"Not Active Parts with Dimensions: {With_Dim_Not_Active}; Percentage with respect to Parts with Dims: {round(With_Dim_Not_Active_Percent, 2)}%\")\n",
    "\n",
    "# Here we find out that a row, if containing 0 in 1 dimension, has 0 in all, or\n",
    "# A row has either all or none dimensions\n",
    "# 16% of Rows has 0 Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "labels = ['Active', 'Not Active'] # Create labels and sizes for the pie chart\n",
    "sizes = [No_Dim_Active_Percent, No_Dim_Not_Active_Percent]\n",
    "\n",
    "plt.figure(figsize=(10, 8)) # Create the pie chart\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, textprops={'fontsize': 20})\n",
    "\n",
    "plt.show() # Show the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize above No Dimensions Data\n",
    "\n",
    "# Create the bar graph\n",
    "plt.figure(figsize=(10, 6)) \n",
    "bars = ['Total Rows', 'No Length/Depth', 'No Width', 'No Height']\n",
    "heights = [100, percent_no_depth, percent_no_width, percent_no_height]\n",
    "\n",
    "plt.bar(bars, heights)\n",
    "plt.title(f'Distribution of Rows with No Dimensions', fontsize=16)\n",
    "plt.ylabel('Percentage of Rows')\n",
    "plt.xticks(rotation=45, fontsize=16)\n",
    "\n",
    "# Add labels to each bar\n",
    "for i, v in enumerate(heights):\n",
    "    plt.text(i, v, str(round(v, 2)) + '%', ha='center', va='bottom')\n",
    "\n",
    "# Show the legend and display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize everything Analyzed above in a single Stacked Bar Chart\n",
    "\n",
    "categories = ['Total Rows', 'Dimensional Rows', 'No Dimensional Rows']\n",
    "values1 = [active, With_Dim_Active, No_Dim_Active]\n",
    "values2 = [total_rows - active, With_Dim_Not_Active, No_Dim_Not_Active]\n",
    "\n",
    "# Create figure and axis objects\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "ax.bar(categories, values1, label='Active', width = 0.3)\n",
    "ax.bar(categories, values2, bottom=values1, label='Not Active', width = 0.3)\n",
    "\n",
    "for i, v in enumerate([total_rows, With_Dim_Active+With_Dim_Not_Active, No_Dim_Active+No_Dim_Not_Active]):\n",
    "    plt.text(i, v, f'Total: {str(v)}', ha='center', va='bottom')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Bar Chart of Active and Non-Active Parts (GParts)')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_yticks(np.linspace(0, 231045, 20))  # Set more ticks on y-axis\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=1)\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wholesale Files Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort 'Sold' Column Descending\n",
    "df_Wholesale = df_Wholesale.sort_values('Sold', ascending=False)\n",
    "if print_df_data_analyse: utils.print_df(df_Wholesale, 100) # Print the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the number of negative sold pcs.\n",
    "neg_sold_count = df_Wholesale[df_Wholesale['Sold'] < 0].shape[0]\n",
    "print(f\"Number of Negative Sold Values: {neg_sold_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Gross Profit' for each unique 'Part Desc.'\n",
    "part_type_profit_sum = df_Wholesale.groupby('Description')['Gross Profit'].sum().reset_index()\n",
    "part_type_profit_sum.columns = ['Part Desc.', 'Total Gross Profit']\n",
    "part_type_profit_sum['Total Gross Profit'] = pd.to_numeric(part_type_profit_sum['Total Gross Profit'], errors='coerce').round()\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_profit_sum = part_type_profit_sum.sort_values('Total Gross Profit', ascending=False)\n",
    "part_type_profit_sum['Total Gross Profit'] = part_type_profit_sum['Total Gross Profit'].round(-1)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_profit_sum, 5)\n",
    "\n",
    "# Visualize using Bar of Top 10\n",
    "top_10 = part_type_profit_sum.head(10)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Gross Profit'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Gross Profit (Wholesale)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Gross Profit', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Gross Profit']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Sold' for each unique 'Part Desc.'\n",
    "part_type_sold_sum = df_Wholesale.groupby('Description')['Sold'].sum().reset_index()\n",
    "part_type_sold_sum.columns = ['Part Desc.', 'Total Sold Pcs.']\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_sold_sum = part_type_sold_sum.sort_values('Total Sold Pcs.', ascending=False)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_sold_sum, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize above part_type_sold_sum using Bar, One Fig of Top 10 Most Sold Part Types and One for Top 50\n",
    "top_10 = part_type_sold_sum.head(10)\n",
    "top_50 = part_type_sold_sum.head(50)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Sold Pieces (Wholesale)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Sold Pcs.']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create the bar chart for Top 50\n",
    "plt.figure(figsize=(9, 6))  # Set the figure size\n",
    "plt.bar(top_50['Part Desc.'], top_50['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 50 Part Types by Total Sold Pieces (Wholesale)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='x', linestyle='--', alpha=1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service File Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count the number of negative sold pcs.\n",
    "neg_sold_count = df_Service[df_Service['Qty Sold'] < 0].shape[0]\n",
    "print(f\"Number of Negative Sold Values: {neg_sold_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Gross Profit' for each unique 'Part Desc.'\n",
    "part_type_profit_sum = df_Service.groupby('Description')['Gross Profit'].sum().reset_index()\n",
    "part_type_profit_sum.columns = ['Part Desc.', 'Total Gross Profit']\n",
    "part_type_profit_sum['Total Gross Profit'] = pd.to_numeric(part_type_profit_sum['Total Gross Profit'], errors='coerce').round()\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_profit_sum = part_type_profit_sum.sort_values('Total Gross Profit', ascending=False)\n",
    "part_type_profit_sum['Total Gross Profit'] = part_type_profit_sum['Total Gross Profit'].round(-1)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_profit_sum, 5)\n",
    "\n",
    "# Visualize using Bar of Top 10\n",
    "top_10 = part_type_profit_sum.head(10)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Gross Profit'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Gross Profit (Service)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Gross Profit', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Gross Profit']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sum up the 'Sold' for each unique 'Part Desc.'\n",
    "part_type_sold_sum = df_Service.groupby('Description')['Qty Sold'].sum().reset_index()\n",
    "part_type_sold_sum.columns = ['Part Desc.', 'Total Sold Pcs.']\n",
    "\n",
    "# Sort the part_type_sold_sum by Total Sold Pcs. in descending order\n",
    "part_type_sold_sum = part_type_sold_sum.sort_values('Total Sold Pcs.', ascending=False)\n",
    "\n",
    "if print_df_data_analyse: utils.print_df(part_type_sold_sum, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize above part_type_sold_sum using Bar, One Fig of Top 10 Most Sold Part Types and One for Top 50\n",
    "top_10 = part_type_sold_sum.head(10)\n",
    "top_50 = part_type_sold_sum.head(50)\n",
    "\n",
    "# Create the bar chart for Top 10\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "plt.bar(top_10['Part Desc.'], top_10['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 10 Part Types by Total Sold Pieces (Service)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for i, v in enumerate(top_10['Total Sold Pcs.']):\n",
    "    plt.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create the bar chart for Top 50\n",
    "plt.figure(figsize=(9, 6))  # Set the figure size\n",
    "plt.bar(top_50['Part Desc.'], top_50['Total Sold Pcs.'], width=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Top 50 Part Types by Total Sold Pieces (Service)', fontsize=20)\n",
    "plt.xlabel('Part Description', fontsize=16)\n",
    "plt.ylabel('Total Sold Pieces', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='x', linestyle='--', alpha=1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Matching Part Numbers between Gparts and each of other Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Number of Matching Part Numbers between GParts and Akins\n",
    "\n",
    "dfs_to_match = [df_Akins, df_Gparts]\n",
    "\n",
    "# Part# Column Name of DFs to Match\n",
    "part_number_columns = ['Part#', 'Svc Part Number']\n",
    "\n",
    "# Find common part numbers\n",
    "common_part_numbers = set(dfs_to_match[0][part_number_columns[0]])\n",
    "for i in range(1, len(dfs_to_match)):\n",
    "    common_part_numbers &= set(dfs_to_match[i][part_number_columns[i]])\n",
    "\n",
    "print(f\"Num of Part numbers common to all DataFrames: {len(common_part_numbers)}\")\n",
    "print(f\"Matching Part Numbers: {common_part_numbers}\")\n",
    "# 10283 Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Number of Matching Part Numbers between GParts and Wholesale\n",
    "\n",
    "dfs_to_match = [df_Wholesale, df_Gparts]\n",
    "\n",
    "# Part# Column Name of DFs to Match\n",
    "part_number_columns = ['Part Number', 'Svc Part Number']\n",
    "\n",
    "# Find common part numbers\n",
    "common_part_numbers = set(dfs_to_match[0][part_number_columns[0]])\n",
    "for i in range(1, len(dfs_to_match)):\n",
    "    common_part_numbers &= set(dfs_to_match[i][part_number_columns[i]])\n",
    "\n",
    "print(f\"Num of Part numbers common to all DataFrames: {len(common_part_numbers)}\")\n",
    "print(f\"Matching Part Numbers: {common_part_numbers}\")\n",
    "# 20763 Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Number of Matching Part Numbers between GParts and Service\n",
    "\n",
    "dfs_to_match = [df_Service, df_Gparts]\n",
    "\n",
    "# Part# Column Name of DFs to Match\n",
    "part_number_columns = ['* indicates a superseded part\\nPart Number', 'Svc Part Number']\n",
    "\n",
    "# Find common part numbers\n",
    "common_part_numbers = set(dfs_to_match[0][part_number_columns[0]])\n",
    "for i in range(1, len(dfs_to_match)):\n",
    "    common_part_numbers &= set(dfs_to_match[i][part_number_columns[i]])\n",
    "\n",
    "print(f\"Num of Part numbers common to all DataFrames: {len(common_part_numbers)}\")\n",
    "print(f\"Matching Part Numbers: {common_part_numbers}\")\n",
    "# 12926 Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Number of Matching Part Numbers between Akins and Wholesale\n",
    "\n",
    "dfs_to_match = [df_Akins, df_Wholesale]\n",
    "\n",
    "# Part# Column Name of DFs to Match\n",
    "part_number_columns = ['Part#', 'Part Number']\n",
    "\n",
    "# Find common part numbers\n",
    "common_part_numbers = set(dfs_to_match[0][part_number_columns[0]])\n",
    "for i in range(1, len(dfs_to_match)):\n",
    "    common_part_numbers &= set(dfs_to_match[i][part_number_columns[i]])\n",
    "\n",
    "print(f\"Num of Part numbers common to all DataFrames: {len(common_part_numbers)}\")\n",
    "print(f\"Matching Part Numbers: {common_part_numbers}\")\n",
    "# 6884 Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Number of Matching Part Numbers between Service and Wholesale\n",
    "\n",
    "dfs_to_match = [df_Service, df_Wholesale]\n",
    "\n",
    "# Part# Column Name of DFs to Match\n",
    "part_number_columns = ['* indicates a superseded part\\nPart Number', 'Part Number']\n",
    "\n",
    "# Find common part numbers\n",
    "common_part_numbers = set(dfs_to_match[0][part_number_columns[0]])\n",
    "for i in range(1, len(dfs_to_match)):\n",
    "    common_part_numbers &= set(dfs_to_match[i][part_number_columns[i]])\n",
    "\n",
    "print(f\"Num of Part numbers common to all DataFrames: {len(common_part_numbers)}\")\n",
    "print(f\"Matching Part Numbers: {common_part_numbers}\")\n",
    "# 6884 Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Sold between Wholesale and Service Matching Part Numbers\n",
    "\n",
    "test = []\n",
    "for cpt in common_part_numbers:\n",
    "    test.append([cpt, df_Wholesale[df_Wholesale['Part Number'] == cpt]['Sold'].values[0], df_Service[df_Service['* indicates a superseded part\\nPart Number'] == cpt]['Qty Sold'].values[0]])\n",
    "\n",
    "df_test = pd.DataFrame(test)\n",
    "utils.print_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Description between Wholesale and Service Matching Part Numbers\n",
    "\n",
    "test = []\n",
    "for cpt in common_part_numbers:\n",
    "    test.append([cpt, df_Wholesale[df_Wholesale['Part Number'] == cpt]['Description'].values[0], df_Service[df_Service['* indicates a superseded part\\nPart Number'] == cpt]['Description'].values[0]])\n",
    "\n",
    "df_test = pd.DataFrame(test)\n",
    "utils.print_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test[1] != df_test[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will have the Columns - 'Part Number', 'Part Desc.', 'Active', 'Sold (Pcs.)', '0Dimensions', 'Length/Depth', 'Width', 'Height', 'Zone', 'Storage Type', 'Sub Storage', 'Number of Storage needed'\n",
    "# It will have all the rows with common part nos. from all 4 Files, having Appropriate Sold Pcs. Values, and Dimensions\n",
    "\n",
    "main_list = []\n",
    "\n",
    "gParts_PartNos = set(df_Gparts['Svc Part Number'])\n",
    "\n",
    "# common_part_numbers = gParts_PartNos & set(df_Akins['Part#'])\n",
    "# for pn, pddesc, ac, s, ld, w, h in zip(common_part_numbers, df_Gparts[\"Svc Part Number Description\"], df_Gparts['Is Active?'], df_Akins['Sold Pcs '], df_Gparts['Prod Att - Length'], df_Gparts['Prod Att- Width'], df_Gparts['Prod Att - Height']):\n",
    "#     main_list.append([pn, pddesc, \"Akins\", ac, s, False, ld, w, h, \"\", \"\", \"\", \"\"])\n",
    "\n",
    "common_part_numbers = gParts_PartNos & set(df_Wholesale['Part Number'])\n",
    "for pn in common_part_numbers:\n",
    "    part_row = df_Gparts[df_Gparts['Svc Part Number'] == pn]\n",
    "    pddesc = part_row[\"Svc Part Number Description\"]\n",
    "    ac = part_row['Is Active?']\n",
    "    s = df_Wholesale[df_Wholesale['Part Number'] == pn]['Sold']\n",
    "    ld =  part_row['Prod Att - Length']\n",
    "    w = part_row['Prod Att- Width']\n",
    "    h = part_row['Prod Att - Height']\n",
    "    main_list.append([pn, pddesc, \"Wholesale\", ac, s, False, ld, w, h, \"\", \"\", \"\", \"\", \"\"])\n",
    "\n",
    "\n",
    "common_part_numbers = gParts_PartNos & set(df_Service['* indicates a superseded part\\nPart Number'])\n",
    "for pn in common_part_numbers:\n",
    "    part_row = df_Gparts[df_Gparts['Svc Part Number'] == pn]\n",
    "    pddesc = part_row[\"Svc Part Number Description\"]\n",
    "    ac = part_row['Is Active?']\n",
    "    s = df_Service[df_Service['* indicates a superseded part\\nPart Number'] == pn]['Sold Qty']\n",
    "    ld =  part_row['Prod Att - Length']\n",
    "    w = part_row['Prod Att- Width']\n",
    "    h = part_row['Prod Att - Height']\n",
    "    main_list.append([pn, pddesc, \"Service\", ac, s, False, ld, w, h, \"\", \"\", \"\", \"\", \"\"])\n",
    "\n",
    "df_Main = pd.DataFrame(main_list)\n",
    "df_Main.columns = ['Part#', 'Part Desc.', 'DataSource', 'Active', 'Sold', '0Dimensions', 'Depth', 'Width', 'Height', 'Zone', 'StorageType', 'SubStorage', 'Num. Storage Required', 'Bin Location']\n",
    "#df_Main = df_Main.sort_values('Sold', ascending=False).reset_index()\n",
    "df_Main[\"Zone\"] = df_Main[\"Zone\"].astype(str)\n",
    "df_Main.loc[(df_Main[\"Depth\"] == 0) | (df_Main[\"Height\"] == 0) | (df_Main[\"Width\"] == 0), \"0Dimensions\"] = True\n",
    "#df_Main = df_Main[df_Main[\"0Dimensions\"] == False].reset_index()\n",
    "#df_Main.drop(['index', 'level_0'], axis=1, inplace=True)\n",
    "#df_Main.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "utils.print_df(df_Main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
